{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfd44932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f766b237",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e841d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\juunho\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "Slow version of gensim.models.doc2vec is being used\n"
     ]
    }
   ],
   "source": [
    "from gensim.summarization import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5e2885f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccda3bae",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98f23ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_json('IMDB_reviews.json', lines=True)\n",
    "df_raw = df_raw[['movie_id','user_id','is_spoiler','review_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7800e19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>plot_synopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0105112</td>\n",
       "      <td>Jack Ryan (Ford) is on a \"working vacation\" in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt1204975</td>\n",
       "      <td>Four boys around the age of 10 are friends in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0040897</td>\n",
       "      <td>Fred Dobbs (Humphrey Bogart) and Bob Curtin (T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0126886</td>\n",
       "      <td>Jim McAllister (Matthew Broderick) is a much-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tt0286716</td>\n",
       "      <td>Bruce Banner (Eric Bana) is a research scienti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    movie_id                                      plot_synopsis\n",
       "0  tt0105112  Jack Ryan (Ford) is on a \"working vacation\" in...\n",
       "1  tt1204975  Four boys around the age of 10 are friends in ...\n",
       "3  tt0040897  Fred Dobbs (Humphrey Bogart) and Bob Curtin (T...\n",
       "4  tt0126886  Jim McAllister (Matthew Broderick) is a much-a...\n",
       "5  tt0286716  Bruce Banner (Eric Bana) is a research scienti..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_detail = pd.read_json('IMDB_movie_details.json', lines=True)\n",
    "df_detail = df_detail[['movie_id','plot_synopsis']]\n",
    "\n",
    "df_detail['plot_synopsis'].replace('', np.nan, inplace=True)\n",
    "df_detail.dropna(subset=['plot_synopsis'], inplace=True)\n",
    "\n",
    "df_detail.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e286f321",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "\n",
    "for i in df_detail['plot_synopsis']:\n",
    "    i= i + str(\". This is second sentence. This is third\")             \n",
    "    a.append(summarize(i, ratio=0.2, split = True))\n",
    "\n",
    "df_detail['Summary'] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "197e059f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_detail['plot_synopsis'] = df_detail['plot_synopsis'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b66de3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0105112</td>\n",
       "      <td>jack ryan (ford) is on a \"working vacation\" in...</td>\n",
       "      <td>[he is seen delivering a lecture at the royal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt1204975</td>\n",
       "      <td>four boys around the age of 10 are friends in ...</td>\n",
       "      <td>[one day they get into a scuffle at a store wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0040897</td>\n",
       "      <td>fred dobbs (humphrey bogart) and bob curtin (t...</td>\n",
       "      <td>[intrigued in the local pub by the stories of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0126886</td>\n",
       "      <td>jim mcallister (matthew broderick) is a much-a...</td>\n",
       "      <td>[jim mcallister (matthew broderick) is a much-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tt0286716</td>\n",
       "      <td>bruce banner (eric bana) is a research scienti...</td>\n",
       "      <td>[his work focuses on using nanomeds and gamma ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>tt0120655</td>\n",
       "      <td>the film opens with a homeless man (bud cort) ...</td>\n",
       "      <td>[the film opens with a homeless man (bud cort)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>tt0276751</td>\n",
       "      <td>will freeman (hugh grant) is a 38-year-old bac...</td>\n",
       "      <td>[he spends most of his free time smoking, watc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>tt0289879</td>\n",
       "      <td>in the year 1998, evan treborn (ashton kutcher...</td>\n",
       "      <td>[in the year 1998, evan treborn (ashton kutche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>tt1723811</td>\n",
       "      <td>brandon (michael fassbender) is a successful, ...</td>\n",
       "      <td>[she has a wedding and engagement ring on, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>tt5013056</td>\n",
       "      <td>the film alternates between three different pe...</td>\n",
       "      <td>[as such, the film follows a non-linear narrat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1339 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       movie_id                                      plot_synopsis  \\\n",
       "0     tt0105112  jack ryan (ford) is on a \"working vacation\" in...   \n",
       "1     tt1204975  four boys around the age of 10 are friends in ...   \n",
       "3     tt0040897  fred dobbs (humphrey bogart) and bob curtin (t...   \n",
       "4     tt0126886  jim mcallister (matthew broderick) is a much-a...   \n",
       "5     tt0286716  bruce banner (eric bana) is a research scienti...   \n",
       "...         ...                                                ...   \n",
       "1563  tt0120655  the film opens with a homeless man (bud cort) ...   \n",
       "1565  tt0276751  will freeman (hugh grant) is a 38-year-old bac...   \n",
       "1567  tt0289879  in the year 1998, evan treborn (ashton kutcher...   \n",
       "1568  tt1723811  brandon (michael fassbender) is a successful, ...   \n",
       "1569  tt5013056  the film alternates between three different pe...   \n",
       "\n",
       "                                                Summary  \n",
       "0     [he is seen delivering a lecture at the royal ...  \n",
       "1     [one day they get into a scuffle at a store wi...  \n",
       "3     [intrigued in the local pub by the stories of ...  \n",
       "4     [jim mcallister (matthew broderick) is a much-...  \n",
       "5     [his work focuses on using nanomeds and gamma ...  \n",
       "...                                                 ...  \n",
       "1563  [the film opens with a homeless man (bud cort)...  \n",
       "1565  [he spends most of his free time smoking, watc...  \n",
       "1567  [in the year 1998, evan treborn (ashton kutche...  \n",
       "1568  [she has a wedding and engagement ring on, and...  \n",
       "1569  [as such, the film follows a non-linear narrat...  \n",
       "\n",
       "[1339 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2ce08e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.summarization.textcleaner import split_sentences\n",
    "def f(seq): # Order preserving unique sentences - sometimes duplicate sentences appear in summaries\n",
    "    seen = set()\n",
    "    return [x for x in seq if x not in seen and not seen.add(x)]\n",
    "\n",
    "def summary(x, perc): #x input document, perc: percentage of the original document to keep\n",
    "    if len(split_sentences(x)) > 10:\n",
    "        test_summary = summarize(x, ratio = perc, split=True)\n",
    "        test_summary = '\\n'.join(map(str, f(test_summary)))\n",
    "    else:\n",
    "        test_summary = x\n",
    "    return test_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4138be48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Picture went to Forrest Gump, while Shawshank and Pulp Fiction were \"just happy to be nominated.\" Of course hindsight is 20/20, but while history looks back on Gump as a good film, Pulp and Redemption are remembered as some of the all-time best.\n",
      "On the DVD, Tim Robbins laughs recounting fans congratulating him on \"that 'Rickshaw' movie.\" Marketing-wise, the film's a nightmare, as 'prison drama' is a tough sell to women, and the story of love between two best friends doesn't spell winner to men.\n",
      "Many movies are about love, many flicks have a side-kick to the hero, but Shawshank is the only one I can think of that looks honestly at the love between two best friends.\n",
      "Besting Forrest and Fiction, it ran solely on strong word of mouth and became the hottest rented film of 1995.\n"
     ]
    }
   ],
   "source": [
    "a =[]\n",
    "\n",
    "for i in df_raw['review_text']:\n",
    "mysummary = summary(df_raw['review_text'].iloc[i], 0.1)\n",
    "print(mysummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b4db092",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "input must have more than one sentence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11696\\356834241.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_raw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_raw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdf_raw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'summaryt'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11696\\2709062726.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(x, perc)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#x input document, perc: percentage of the original document to keep\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_sentences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mtest_summary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msummarize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mperc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mtest_summary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_summary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\juunho\\lib\\site-packages\\gensim\\summarization\\summarizer.py\u001b[0m in \u001b[0;36msummarize\u001b[1;34m(text, ratio, word_count, split)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;31m# If only one sentence is present, the function raises an error (Avoids ZeroDivisionError).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"input must have more than one sentence\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;31m# Warns if the text is too short.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: input must have more than one sentence"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "\n",
    "for i in range(df_raw.count()[0]):\n",
    "    a = summary(df_raw.iloc[i][3], 0.01)\n",
    "\n",
    "df_raw['summaryt'] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771abb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarityValue = []\n",
    "\n",
    "for i in tqdm(range(df.count()[0])):\n",
    "    sentence_1 = nlp(df.iloc[i][3])\n",
    "    sentence_2 = nlp(df.iloc[i][4])\n",
    "    similarityValue.append(sentence_1.similarity(sentence_2))\n",
    "\n",
    "df['Similarity'] = similarityValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86cb69a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "input must have more than one sentence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11696\\3200714325.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_raw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'review_text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\". This is second sentence. This is third\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummarize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdf_raw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Summary'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\juunho\\lib\\site-packages\\gensim\\summarization\\summarizer.py\u001b[0m in \u001b[0;36msummarize\u001b[1;34m(text, ratio, word_count, split)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;31m# If only one sentence is present, the function raises an error (Avoids ZeroDivisionError).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"input must have more than one sentence\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;31m# Warns if the text is too short.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: input must have more than one sentence"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "\n",
    "for i in df_raw['review_text']:\n",
    "    i= i + str(\". This is second sentence. This is third\")             \n",
    "    a.append(summarize(i, ratio=0.9, split = True))\n",
    "\n",
    "df_raw['Summary'] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f108d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_snowstemming(tokenized_column):\n",
    "    stemmer = SnowballStemmer('english') \n",
    "    return [stemmer.stem(word) for word in tokenized_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed21eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def track(column):\n",
    "    keyword = []\n",
    "    stopwords = list(STOP_WORDS)\n",
    "    pos_tag = ['PROPN','ADJ','NOUN','VERB']\n",
    "    return\n",
    "    for token in doc:\n",
    "             if(token.text in stopwords or token.text in punctuation):\n",
    "                continue\n",
    "                if(token.pos_ in pos_tag):\n",
    "                    keyword.append(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340d7f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceb23bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw['review_text'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19444071",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw['Summary'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301eb17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def track(column):\n",
    "    doc = nlp(column)\n",
    "    return\n",
    "    for token in doc:\n",
    "             if(token.text in stopwords or token.text in punctuation):\n",
    "                continue\n",
    "                if(token.pos_ in pos_tag):\n",
    "                    keyword.append(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dd8130",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw['review_text_st'] = df_raw.apply(lambda x: track(x['review_text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e6b3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba97433",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = []\n",
    "stopwords = list(STOP_WORDS)\n",
    "pos_tag = ['PROPN','ADJ','NOUN','VERB']\n",
    "\n",
    "for i in range(df_raw.count()[0]):\n",
    "    doc = nlp(df_raw.iloc[i][3])\n",
    "\n",
    "    for token in doc:\n",
    "            if(token.text in stopwords or token.text in punctuation):\n",
    "                continue\n",
    "            if(token.pos_ in pos_tag):\n",
    "                keyword.append(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adba4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = []\n",
    "stopwords = list(STOP_WORDS)\n",
    "pos_tag = ['PROPN','ADJ','NOUN','VERB']\n",
    "\n",
    "for i in range(df_raw.count()[0]):\n",
    "    doc = nlp(df_raw.iloc[i][3])\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cdef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_word = Counter(keyword)\n",
    "freq_word.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5194548",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(freq_word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "juunho",
   "language": "python",
   "name": "juunho"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
