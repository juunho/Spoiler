{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfd44932",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed: 지정된 모듈을 찾을 수 없습니다.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9348\\877137118.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSnowballStemmer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummarization\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msummarize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\juunho\\lib\\site-packages\\gensim\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparsing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterfaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutils\u001b[0m  \u001b[1;31m# noqa:F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\juunho\\lib\\site-packages\\gensim\\corpora\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# bring corpus classes directly into package namespace, to save some typing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mindexedcorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mIndexedCorpus\u001b[0m  \u001b[1;31m# noqa:F401 must appear before the other classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmmcorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMmCorpus\u001b[0m  \u001b[1;31m# noqa:F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\juunho\\lib\\site-packages\\gensim\\corpora\\indexedcorpus.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minterfaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mlogger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\juunho\\lib\\site-packages\\gensim\\interfaces.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\juunho\\lib\\site-packages\\gensim\\matutils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlapack\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_lapack_funcs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\juunho\\lib\\site-packages\\scipy\\stats\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    439\u001b[0m \"\"\"\n\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmorestats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\juunho\\lib\\site-packages\\scipy\\stats\\stats.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mspecial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmstats_basic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m from ._stats_mstats_common import (_find_repeats, linregress, theilslopes,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\juunho\\lib\\site-packages\\scipy\\stats\\distributions.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#       instead of `git blame -Lxxx,+x`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_distn_infrastructure\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrv_discrete\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrv_continuous\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrv_frozen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_continuous_distns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\juunho\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# for root finding for continuous distribution ppf, and max likelihood\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# estimation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# for functions of continuous distributions (e.g. moments, entropy, cdf)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\juunho\\lib\\site-packages\\scipy\\optimize\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mnonlin\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mslsqp\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfmin_slsqp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_nnls\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnnls\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_basinhopping\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbasinhopping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_linprog\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinprog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinprog_verbose_callback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed: 지정된 모듈을 찾을 수 없습니다."
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer, PorterStemmer\n",
    "from collections import OrderedDict\n",
    "from gensim.summarization import summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0d6b79",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98f23ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>plot_synopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0105112</td>\n",
       "      <td>Jack Ryan (Ford) is on a \"working vacation\" in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt1204975</td>\n",
       "      <td>Four boys around the age of 10 are friends in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0040897</td>\n",
       "      <td>Fred Dobbs (Humphrey Bogart) and Bob Curtin (T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0126886</td>\n",
       "      <td>Jim McAllister (Matthew Broderick) is a much-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tt0286716</td>\n",
       "      <td>Bruce Banner (Eric Bana) is a research scienti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    movie_id                                      plot_synopsis\n",
       "0  tt0105112  Jack Ryan (Ford) is on a \"working vacation\" in...\n",
       "1  tt1204975  Four boys around the age of 10 are friends in ...\n",
       "3  tt0040897  Fred Dobbs (Humphrey Bogart) and Bob Curtin (T...\n",
       "4  tt0126886  Jim McAllister (Matthew Broderick) is a much-a...\n",
       "5  tt0286716  Bruce Banner (Eric Bana) is a research scienti..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_detail = pd.read_json('IMDB_movie_details.json', lines=True)\n",
    "df_detail = df_detail[['movie_id','plot_synopsis']]\n",
    "\n",
    "df_detail['plot_synopsis'].replace('', np.nan, inplace=True)\n",
    "df_detail.dropna(subset=['plot_synopsis'], inplace=True)\n",
    "\n",
    "df_detail.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1d793b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_spoiler</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur1898687</td>\n",
       "      <td>True</td>\n",
       "      <td>In its Oscar year, Shawshank Redemption (writt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur0842118</td>\n",
       "      <td>True</td>\n",
       "      <td>The Shawshank Redemption is without a doubt on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur1285640</td>\n",
       "      <td>True</td>\n",
       "      <td>I believe that this film is the best story eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur1003471</td>\n",
       "      <td>True</td>\n",
       "      <td>**Yes, there are SPOILERS here**This film has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur0226855</td>\n",
       "      <td>True</td>\n",
       "      <td>At the heart of this extraordinary movie is a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    movie_id    user_id  is_spoiler  \\\n",
       "0  tt0111161  ur1898687        True   \n",
       "1  tt0111161  ur0842118        True   \n",
       "2  tt0111161  ur1285640        True   \n",
       "3  tt0111161  ur1003471        True   \n",
       "4  tt0111161  ur0226855        True   \n",
       "\n",
       "                                         review_text  \n",
       "0  In its Oscar year, Shawshank Redemption (writt...  \n",
       "1  The Shawshank Redemption is without a doubt on...  \n",
       "2  I believe that this film is the best story eve...  \n",
       "3  **Yes, there are SPOILERS here**This film has ...  \n",
       "4  At the heart of this extraordinary movie is a ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = pd.read_json('IMDB_reviews.json', lines=True)\n",
    "df_raw = df_raw[['movie_id','user_id','is_spoiler','review_text']]\n",
    "\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "860aa2f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = []\n",
    "\n",
    "for i in df_detail['plot_synopsis']:\n",
    "    i= i + str(\". This is second sentence. This is third\")             \n",
    "    a.append(summarize(i, ratio=0.4, split = True))\n",
    "\n",
    "df_detail['summary'] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fc2d10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_detail['summary'] = [','.join(map(str, l)) for l in df_detail['summary']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f960ab3b",
   "metadata": {},
   "source": [
    "### Lower-case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdd51f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_detail['plot_synopsis'] = df_detail['summary'].str.lower()\n",
    "df_raw['review_text'] = df_raw['review_text'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daccc5d",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a885e552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(column):\n",
    "    tokens = nltk.word_tokenize(column)\n",
    "    return [w for w in tokens if w.isalpha()]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b05ca45d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>r_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in its oscar year, shawshank redemption (writt...</td>\n",
       "      <td>[in, its, oscar, year, shawshank, redemption, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the shawshank redemption is without a doubt on...</td>\n",
       "      <td>[the, shawshank, redemption, is, without, a, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i believe that this film is the best story eve...</td>\n",
       "      <td>[i, believe, that, this, film, is, the, best, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>**yes, there are spoilers here**this film has ...</td>\n",
       "      <td>[yes, there, are, spoilers, here, this, film, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>at the heart of this extraordinary movie is a ...</td>\n",
       "      <td>[at, the, heart, of, this, extraordinary, movi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  \\\n",
       "0  in its oscar year, shawshank redemption (writt...   \n",
       "1  the shawshank redemption is without a doubt on...   \n",
       "2  i believe that this film is the best story eve...   \n",
       "3  **yes, there are spoilers here**this film has ...   \n",
       "4  at the heart of this extraordinary movie is a ...   \n",
       "\n",
       "                                         r_tokenized  \n",
       "0  [in, its, oscar, year, shawshank, redemption, ...  \n",
       "1  [the, shawshank, redemption, is, without, a, d...  \n",
       "2  [i, believe, that, this, film, is, the, best, ...  \n",
       "3  [yes, there, are, spoilers, here, this, film, ...  \n",
       "4  [at, the, heart, of, this, extraordinary, movi...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_detail['p_tokenized'] = df_detail.apply(lambda x: tokenize(x['plot_synopsis']), axis=1)\n",
    "df_raw['r_tokenized'] = df_raw.apply(lambda x: tokenize(x['review_text']), axis=1)\n",
    "\n",
    "df_raw[['review_text', 'r_tokenized']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc995156",
   "metadata": {},
   "source": [
    "### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a48bc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokenized_column):\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    return [word for word in tokenized_column if not word in stops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7579b0e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>r_stopwords_removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in its oscar year, shawshank redemption (writt...</td>\n",
       "      <td>[oscar, year, shawshank, redemption, written, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the shawshank redemption is without a doubt on...</td>\n",
       "      <td>[shawshank, redemption, without, doubt, one, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i believe that this film is the best story eve...</td>\n",
       "      <td>[believe, film, best, story, ever, told, film,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>**yes, there are spoilers here**this film has ...</td>\n",
       "      <td>[yes, spoilers, film, emotional, impact, find,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>at the heart of this extraordinary movie is a ...</td>\n",
       "      <td>[heart, extraordinary, movie, brilliant, indel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  \\\n",
       "0  in its oscar year, shawshank redemption (writt...   \n",
       "1  the shawshank redemption is without a doubt on...   \n",
       "2  i believe that this film is the best story eve...   \n",
       "3  **yes, there are spoilers here**this film has ...   \n",
       "4  at the heart of this extraordinary movie is a ...   \n",
       "\n",
       "                                 r_stopwords_removed  \n",
       "0  [oscar, year, shawshank, redemption, written, ...  \n",
       "1  [shawshank, redemption, without, doubt, one, b...  \n",
       "2  [believe, film, best, story, ever, told, film,...  \n",
       "3  [yes, spoilers, film, emotional, impact, find,...  \n",
       "4  [heart, extraordinary, movie, brilliant, indel...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_detail['p_stopwords_removed'] = df_detail.apply(lambda x: remove_stopwords(x['p_tokenized']), axis=1)\n",
    "df_raw['r_stopwords_removed'] = df_raw.apply(lambda x: remove_stopwords(x['r_tokenized']), axis=1)\n",
    "\n",
    "df_raw[['review_text', 'r_stopwords_removed']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305a29f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5d19be7",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ec707ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_snowstemming(tokenized_column):\n",
    "    stemmer = SnowballStemmer('english') \n",
    "    return [stemmer.stem(word) for word in tokenized_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c36f4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_porterstemming(tokenized_column):\n",
    "    stemmer = PorterStemmer() \n",
    "    return [stemmer.stem(word) for word in tokenized_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c9ef97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_detail['p_snowball_stemmed'] = df_detail.apply(lambda x: apply_snowstemming(x['p_stopwords_removed']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "360d3b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>r_snowball_stemmed</th>\n",
       "      <th>r_porter_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in its oscar year, shawshank redemption (writt...</td>\n",
       "      <td>[oscar, year, shawshank, redempt, written, dir...</td>\n",
       "      <td>[oscar, year, shawshank, redempt, written, dir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the shawshank redemption is without a doubt on...</td>\n",
       "      <td>[shawshank, redempt, without, doubt, one, bril...</td>\n",
       "      <td>[shawshank, redempt, without, doubt, one, bril...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i believe that this film is the best story eve...</td>\n",
       "      <td>[believ, film, best, stori, ever, told, film, ...</td>\n",
       "      <td>[believ, film, best, stori, ever, told, film, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>**yes, there are spoilers here**this film has ...</td>\n",
       "      <td>[yes, spoiler, film, emot, impact, find, hard,...</td>\n",
       "      <td>[ye, spoiler, film, emot, impact, find, hard, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>at the heart of this extraordinary movie is a ...</td>\n",
       "      <td>[heart, extraordinari, movi, brilliant, indel,...</td>\n",
       "      <td>[heart, extraordinari, movi, brilliant, indel,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  \\\n",
       "0  in its oscar year, shawshank redemption (writt...   \n",
       "1  the shawshank redemption is without a doubt on...   \n",
       "2  i believe that this film is the best story eve...   \n",
       "3  **yes, there are spoilers here**this film has ...   \n",
       "4  at the heart of this extraordinary movie is a ...   \n",
       "\n",
       "                                  r_snowball_stemmed  \\\n",
       "0  [oscar, year, shawshank, redempt, written, dir...   \n",
       "1  [shawshank, redempt, without, doubt, one, bril...   \n",
       "2  [believ, film, best, stori, ever, told, film, ...   \n",
       "3  [yes, spoiler, film, emot, impact, find, hard,...   \n",
       "4  [heart, extraordinari, movi, brilliant, indel,...   \n",
       "\n",
       "                                    r_porter_stemmed  \n",
       "0  [oscar, year, shawshank, redempt, written, dir...  \n",
       "1  [shawshank, redempt, without, doubt, one, bril...  \n",
       "2  [believ, film, best, stori, ever, told, film, ...  \n",
       "3  [ye, spoiler, film, emot, impact, find, hard, ...  \n",
       "4  [heart, extraordinari, movi, brilliant, indel,...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw['r_snowball_stemmed'] = df_raw.apply(lambda x: apply_snowstemming(x['r_stopwords_removed']), axis=1)\n",
    "df_raw['r_porter_stemmed'] = df_raw.apply(lambda x: apply_porterstemming(x['r_stopwords_removed']), axis=1)\n",
    "\n",
    "df_raw[['review_text', 'r_snowball_stemmed', 'r_porter_stemmed']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200c9e32",
   "metadata": {},
   "source": [
    "### Rejoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "119133d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rejoin_words(tokenized_column):\n",
    "    \n",
    "    return ( \" \".join(tokenized_column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0a65e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in its oscar year, shawshank redemption (writt...</td>\n",
       "      <td>oscar year shawshank redempt written direct fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the shawshank redemption is without a doubt on...</td>\n",
       "      <td>shawshank redempt without doubt one brilliant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i believe that this film is the best story eve...</td>\n",
       "      <td>believ film best stori ever told film tell rob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>**yes, there are spoilers here**this film has ...</td>\n",
       "      <td>yes spoiler film emot impact find hard write c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>at the heart of this extraordinary movie is a ...</td>\n",
       "      <td>heart extraordinari movi brilliant indel perfo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  \\\n",
       "0  in its oscar year, shawshank redemption (writt...   \n",
       "1  the shawshank redemption is without a doubt on...   \n",
       "2  i believe that this film is the best story eve...   \n",
       "3  **yes, there are spoilers here**this film has ...   \n",
       "4  at the heart of this extraordinary movie is a ...   \n",
       "\n",
       "                                              review  \n",
       "0  oscar year shawshank redempt written direct fr...  \n",
       "1  shawshank redempt without doubt one brilliant ...  \n",
       "2  believ film best stori ever told film tell rob...  \n",
       "3  yes spoiler film emot impact find hard write c...  \n",
       "4  heart extraordinari movi brilliant indel perfo...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_detail['synopsis'] = df_detail.apply(lambda x: rejoin_words(x['p_snowball_stemmed']), axis=1)\n",
    "df_raw['review'] = df_raw.apply(lambda x: rejoin_words(x['r_snowball_stemmed']), axis=1)\n",
    "\n",
    "df_raw[['review_text', 'review']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5d762c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oscar year shawshank redempt written direct frank darabont novella rita hayworth shawshank redempt stephen king nomin seven academi award walk away zero best pictur went forrest gump shawshank pulp fiction happi nomin cours hindsight histori look back gump good film pulp redempt rememb best pulp howev success word go make huge splash cann make american master two film andi dufresn success come easi fortun failur life open screen take film fell fast theatr finish mere reason failur mani first titl clunker icon fan today peopl knew care dvd tim robbin laugh recount fan congratul movi film nightmar drama tough sell women stori love two best friend spell winner men worst movi slow molass desson thomson write washington post wander subplot everi opportun ignor abund narrat exit point settl final weak make film set open aerial shot prison total amaz piec architectur strong gothic design immedi prison becom charact cast shadow film tall stone wall stretch everi shot tower men contain blot memori outsid world andi robbin hold onto hope music sandi beach zihuatanejo need say need forget forget place world made stone someth insid ca touch red morgan freeman think much andi first pick tall glass milk silver spoon ass first new fish crack andi say word lose bet red resent time two get know quick becom best friend one film major strength mani movi love mani flick hero shawshank one think look honest love two best friend seem odd hollywood would skip relationship time feel weigh much everyon day day live perhap sentiment seem convent shawshank core friendship hit right note film much better pace deliber well spend film watch actor easi forget movi timelin span well year huge measur time would pass slowli realiti would amplifi prison film lack interest moment still know go mere intend take sweet time get pay well tedium prison life make climax much exhilar anyon see moment never theme faith hope definit religi subtext found quiet selfless carefre andi obvious christ figur warden norton bob gunton obvious model richard nixon day close personifi satan come look subtext movi speak anyon search hope compel drama move film perfect written act shot come much better score shawshank redempt serv messag hope hollywood well film memori prove life box offic best forrest fiction ran sole strong word mouth becam hottest rent film current sit imdb top film occasion swap spot godfath top rank film time redempt inde seen yet hell wait andi say come simpl choic realli either get busi live get busi die'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw['review'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03e5ee5",
   "metadata": {},
   "source": [
    "### Remove Duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8eba8bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw['review'] = (df_raw['review'].str.split()\n",
    "                              .apply(lambda x: OrderedDict.fromkeys(x).keys())\n",
    "                              .str.join(' '))\n",
    "\n",
    "df_detail['synopsis'] = (df_detail['synopsis'].str.split()\n",
    "                              .apply(lambda x: OrderedDict.fromkeys(x).keys())\n",
    "                              .str.join(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66f20e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oscar year shawshank redempt written direct frank darabont novella rita hayworth stephen king nomin seven academi award walk away zero best pictur went forrest gump pulp fiction happi cours hindsight histori look back good film rememb howev success word go make huge splash cann american master two andi dufresn come easi fortun failur life open screen take fell fast theatr finish mere reason mani first titl clunker icon fan today peopl knew care dvd tim robbin laugh recount congratul movi nightmar drama tough sell women stori love friend spell winner men worst slow molass desson thomson write washington post wander subplot everi opportun ignor abund narrat exit point settl final weak set aerial shot prison total amaz piec architectur strong gothic design immedi becom charact cast shadow tall stone wall stretch tower contain blot memori outsid world hold onto hope music sandi beach zihuatanejo need say forget place made someth insid ca touch red morgan freeman think much pick glass milk silver spoon ass new fish crack lose bet resent time get know quick one major strength flick hero honest seem odd hollywood would skip relationship feel weigh everyon day live perhap sentiment convent core friendship hit right note better pace deliber well spend watch actor timelin span measur pass slowli realiti amplifi lack interest moment still intend sweet pay tedium climax exhilar anyon see never theme faith definit religi subtext found quiet selfless carefre obvious christ figur warden norton bob gunton model richard nixon close personifi satan speak search compel move perfect act score serv messag prove box offic ran sole mouth becam hottest rent current sit imdb top occasion swap spot godfath rank inde seen yet hell wait simpl choic realli either busi die'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw['review'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a73a80d",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "026c51ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_synopsis = df_detail[['movie_id','synopsis']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f7fd73b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>synopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0105112</td>\n",
       "      <td>seen deliv lectur royal naval academi ryan wif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt1204975</td>\n",
       "      <td>one day get scuffl store young thug steal bott...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0040897</td>\n",
       "      <td>intrigu local pub stori howard walter huston o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0126886</td>\n",
       "      <td>jim mcallist matthew broderick high school his...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tt0286716</td>\n",
       "      <td>work focus use nanom gamma radiat cure cancer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>tt0120655</td>\n",
       "      <td>film open homeless man bud cort desert new jer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>tt0276751</td>\n",
       "      <td>spend free time smoke watch televis read pop s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>tt0289879</td>\n",
       "      <td>year evan treborn ashton kutcher suffer sever ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>tt1723811</td>\n",
       "      <td>wed engag ring exit train disappear work brand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>tt5013056</td>\n",
       "      <td>film follow open text read world war ii britis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1339 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       movie_id                                           synopsis\n",
       "0     tt0105112  seen deliv lectur royal naval academi ryan wif...\n",
       "1     tt1204975  one day get scuffl store young thug steal bott...\n",
       "3     tt0040897  intrigu local pub stori howard walter huston o...\n",
       "4     tt0126886  jim mcallist matthew broderick high school his...\n",
       "5     tt0286716  work focus use nanom gamma radiat cure cancer ...\n",
       "...         ...                                                ...\n",
       "1563  tt0120655  film open homeless man bud cort desert new jer...\n",
       "1565  tt0276751  spend free time smoke watch televis read pop s...\n",
       "1567  tt0289879  year evan treborn ashton kutcher suffer sever ...\n",
       "1568  tt1723811  wed engag ring exit train disappear work brand...\n",
       "1569  tt5013056  film follow open text read world war ii britis...\n",
       "\n",
       "[1339 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_synopsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df9cc525",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review = df_raw[['movie_id','user_id','is_spoiler','review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bf9ab56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_spoiler</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur1898687</td>\n",
       "      <td>True</td>\n",
       "      <td>oscar year shawshank redempt written direct fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur0842118</td>\n",
       "      <td>True</td>\n",
       "      <td>shawshank redempt without doubt one brilliant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur1285640</td>\n",
       "      <td>True</td>\n",
       "      <td>believ film best stori ever told tell robbin p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur1003471</td>\n",
       "      <td>True</td>\n",
       "      <td>yes spoiler film emot impact find hard write c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur0226855</td>\n",
       "      <td>True</td>\n",
       "      <td>heart extraordinari movi brilliant indel perfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573908</th>\n",
       "      <td>tt0139239</td>\n",
       "      <td>ur0100166</td>\n",
       "      <td>False</td>\n",
       "      <td>go wise fast pure entertain assembl except cas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573909</th>\n",
       "      <td>tt0139239</td>\n",
       "      <td>ur0021767</td>\n",
       "      <td>False</td>\n",
       "      <td>well shall say fun rate three plotlin origin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573910</th>\n",
       "      <td>tt0139239</td>\n",
       "      <td>ur0392750</td>\n",
       "      <td>False</td>\n",
       "      <td>go best movi ever seen lot read review notic m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573911</th>\n",
       "      <td>tt0139239</td>\n",
       "      <td>ur0349105</td>\n",
       "      <td>False</td>\n",
       "      <td>call teenag version pulp fiction whatev want p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573912</th>\n",
       "      <td>tt0139239</td>\n",
       "      <td>ur0156431</td>\n",
       "      <td>False</td>\n",
       "      <td>movi made doubt sucker mtv faith mani care any...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>573913 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         movie_id    user_id  is_spoiler  \\\n",
       "0       tt0111161  ur1898687        True   \n",
       "1       tt0111161  ur0842118        True   \n",
       "2       tt0111161  ur1285640        True   \n",
       "3       tt0111161  ur1003471        True   \n",
       "4       tt0111161  ur0226855        True   \n",
       "...           ...        ...         ...   \n",
       "573908  tt0139239  ur0100166       False   \n",
       "573909  tt0139239  ur0021767       False   \n",
       "573910  tt0139239  ur0392750       False   \n",
       "573911  tt0139239  ur0349105       False   \n",
       "573912  tt0139239  ur0156431       False   \n",
       "\n",
       "                                                   review  \n",
       "0       oscar year shawshank redempt written direct fr...  \n",
       "1       shawshank redempt without doubt one brilliant ...  \n",
       "2       believ film best stori ever told tell robbin p...  \n",
       "3       yes spoiler film emot impact find hard write c...  \n",
       "4       heart extraordinari movi brilliant indel perfo...  \n",
       "...                                                   ...  \n",
       "573908  go wise fast pure entertain assembl except cas...  \n",
       "573909  well shall say fun rate three plotlin origin o...  \n",
       "573910  go best movi ever seen lot read review notic m...  \n",
       "573911  call teenag version pulp fiction whatev want p...  \n",
       "573912  movi made doubt sucker mtv faith mani care any...  \n",
       "\n",
       "[573913 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7edf0253",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spoiler = pd.merge(df_review, df_synopsis, how='inner', on ='movie_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03324458",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_spoiler.to_csv('IMDB/dataset/gensim-spacy-pre-unq.csv', index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "juunho",
   "language": "python",
   "name": "juunho"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
